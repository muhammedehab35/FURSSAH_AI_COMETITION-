{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OicYSU_s6xzM"
      },
      "source": [
        "## Mount Your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzExaTCGnZRF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDV3lCZHxwOe"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhrM7Kgyxydu"
      },
      "outputs": [],
      "source": [
        "!pip install -qU transformers==4.48.3 datasets==3.2.0 optimum==1.24.0\n",
        "!pip install -qU openai==1.61.0 wandb\n",
        "!pip install -qU json-repair==0.29.1\n",
        "!pip install -qU faker==35.2.0\n",
        "!pip install -qU vllm==0.7.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8526F9lVKilu"
      },
      "outputs": [],
      "source": [
        "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
        "!cd LLaMA-Factory && pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65ZhrnavyL0Q"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import wandb\n",
        "\n",
        "wandb.login(key=userdata.get('wandb'))\n",
        "hf_token = userdata.get('huggingface')\n",
        "!huggingface-cli login --token {hf_token}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLdOa2oSyuBE"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8utsMq7y_TP"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from os.path import join\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "import requests\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional, Literal\n",
        "from datetime import datetime\n",
        "\n",
        "import json_repair\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "data_dir = \"/gdrive/MyDrive/youtube-resources/llm-finetuning\"\n",
        "base_model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "\n",
        "device = \"cuda\"\n",
        "torch_dtype = None\n",
        "\n",
        "def parse_json(text):\n",
        "    try:\n",
        "        return json_repair.loads(text)\n",
        "    except:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShkKHFV-01gy"
      },
      "outputs": [],
      "source": [
        "story = \"\"\"\n",
        "Course Title: Reinforcement Learning (21h)\n",
        "Duration: 7 weeks (3h per week)\n",
        "Reference: Sutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An Introduction.\n",
        "Course Learning Outcomes (CLOs):\n",
        "By the end of the course, students will be able to:\n",
        "Explain fundamental concepts of Reinforcement Learning (RL) and its differences from other Machine Learning paradigms. (Understand - Level 2)\n",
        "Formulate decision-making problems as Markov Decision Processes (MDPs). (Apply - Level 3)\n",
        "Implement RL algorithms, including Dynamic Programming, Monte Carlo methods, Temporal Difference learning, Q-learning, and Deep Q Networks (DQN). (Apply - Level 3)\n",
        "Analyze trade-offs between model-based and model-free RL, and policy-based vs. value-based approaches. (Analyze - Level 4)\n",
        "Evaluate the performance of RL agents in various environments. (Evaluate - Level 5)\n",
        "Discuss recent RL advancements, such as Deep RL and applications like ChatGPT. (Evaluate - Level 5)\n",
        "Course Outline (Week-by-Week Plan)\n",
        "Week 1: Introduction to Reinforcement Learning\n",
        "Topics:\n",
        "What is RL?\n",
        "Differences between RL, supervised, and unsupervised learning.\n",
        "Examples of RL applications.\n",
        "Elements of an RL problem: agents, states, actions, rewards.\n",
        "Exploration vs. Exploitation.\n",
        "ILO:\n",
        "Explain how RL differs from other ML paradigms. (Understand - Level 2)\n",
        "Describe fundamental RL concepts. (Understand - Level 2)\n",
        "Activity: Discussion on real-world RL applications (e.g., robotics, gaming, recommendation systems).\n",
        "\n",
        "\n",
        "Week 2: Markov Decision Processes (MDPs)\n",
        "Topics:\n",
        "Definition of an MDP.\n",
        "States, actions, transition probabilities, rewards, discounting.\n",
        "Bellman equations.\n",
        "ILO:\n",
        "Formulate problems as MDPs. (Apply - Level 3)\n",
        "Solve simple MDPs using Bellman equations. (Apply - Level 3)\n",
        "Activity: Hands-on exercise translating real-world problems into MDPs.\n",
        "\n",
        "Week 3: Dynamic Programming (DP)\n",
        "Topics:\n",
        "Policy evaluation.\n",
        "Policy iteration vs. value iteration.\n",
        "Limitations of DP.\n",
        "ILO:\n",
        "Implement policy evaluation and policy iteration. (Apply - Level 3)\n",
        "Analyze the limitations of DP in large state spaces. (Analyze - Level 4)\n",
        "Activity: Coding DP-based value iteration.\n",
        "\n",
        "Week 4: Monte Carlo and Temporal Difference Learning\n",
        "Topics:\n",
        "Monte Carlo methods for estimating returns.\n",
        "Temporal Difference (TD) learning: TD(0), TD(λ).\n",
        "Eligibility traces.\n",
        "ILO:\n",
        "Compare Monte Carlo and TD methods. (Analyze - Level 4)\n",
        "Implement Monte Carlo and TD algorithms. (Apply - Level 3)\n",
        "Activity: Implementing first-visit Monte Carlo and TD(0) in Python.\n",
        "Week 5: Model-Free Learning and Q-Learning\n",
        "Topics:\n",
        "Model-based vs. model-free RL.\n",
        "Q-learning and SARSA.\n",
        "Off-policy vs. on-policy learning.\n",
        "Function approximation in RL.\n",
        "ILO:\n",
        "Differentiate model-based and model-free approaches. (Understand - Level 2)\n",
        "Implement Q-learning and SARSA. (Apply - Level 3)\n",
        "Evaluate the impact of function approximation on RL. (Evaluate - Level 5)\n",
        "Activity: Coding Q-learning in an OpenAI Gym environment.\n",
        "\n",
        "Week 6: Deep Reinforcement Learning & DQN\n",
        "Topics:\n",
        "Introduction to Deep RL.\n",
        "Deep Q Networks (DQN) and experience replay.\n",
        "Policy-based RL: REINFORCE, Actor-Critic methods.\n",
        "ILO:\n",
        "Implement a DQN using PyTorch/TensorFlow. (Apply - Level 3)\n",
        "Analyze the stability issues in Deep RL. (Analyze - Level 4)\n",
        "Activity: Training a DQN on a simple RL task (CartPole).\n",
        "\n",
        "Week 7: RL at Scale & Recent Use Cases\n",
        "Topics:\n",
        "RL in the large: sample efficiency, generalization, scaling RL models.\n",
        "RL in ChatGPT and large-scale AI systems.\n",
        "Ethical and practical concerns in RL applications.\n",
        "ILO:\n",
        "Discuss large-scale RL challenges. (Evaluate - Level 5)\n",
        "Analyze RL applications in NLP (e.g., ChatGPT). (Analyze - Level 4)\n",
        "Activity: Case study on RLHF (Reinforcement Learning from Human Feedback) in ChatGPT.\n",
        "\n",
        "Assessment and Evaluation\n",
        "Assessment\tWeight (%)\tCLOs Assessed\n",
        "Coding Labs\t30%\t3, 4, 5\n",
        "Final EXAM (MCQs)\t40%\t1, 2, 3, 4, 5, 6\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hkuh7dM08Zk"
      },
      "source": [
        "### Details Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "news_details_example = NewsDetails(\n",
        "    story_title=\"Recent Advancements in Deep Reinforcement Learning\",\n",
        "    story_keywords=[\"Deep Reinforcement Learning\", \"Artificial Intelligence\", \"Reinforcement Learning\"],\n",
        "    story_summary=[\n",
        "        \"Deep Q Networks have revolutionized RL tasks.\",\n",
        "        \"Recent work by researchers like Silver and Mnih has advanced RL capabilities.\",\n",
        "        \"Applications of RL are growing in fields such as robotics and natural language processing.\"\n",
        "    ],\n",
        "    story_category=\"technology\",\n",
        "    story_entities=[\n",
        "        Entity(entity_value=\"Richard S. Sutton\", entity_type=\"person-male\"),\n",
        "        Entity(entity_value=\"Andrew G. Barto\", entity_type=\"person-male\"),\n",
        "        Entity(entity_value=\"David Silver\", entity_type=\"person-male\"),\n",
        "        Entity(entity_value=\"Volodymyr Mnih\", entity_type=\"person-male\"),\n",
        "        Entity(entity_value=\"Deep Q Networks\", entity_type=\"product\"),\n",
        "        Entity(entity_value=\"Reinforcement Learning\", entity_type=\"technology\")\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Entity(BaseModel):\n",
        "    entity_value: str = Field(..., description=\"The actual name or value of the entity.\")\n",
        "    entity_type: EntityType = Field(..., description=\"The type of recognized entity.\")\n",
        "class NewsDetails(BaseModel):\n",
        "    story_title: str = Field(..., min_length=5, max_length=300,\n",
        "                             description=\"A focused title that explains the main concept or algorithm in Reinforcement Learning.\")\n",
        "\n",
        "    story_keywords: List[str] = Field(..., min_items=1,\n",
        "                                      description=\"Important keywords related to the story. For RL: Q-learning, Bellman Equation, MDP.\")\n",
        "\n",
        "    story_summary: List[str] = Field(\n",
        "                                    ..., min_items=1, max_items=5,\n",
        "                                    description=\"Concise summary of key points. Key RL concepts, algorithms, and mathematical formulation.\"\n",
        "                                )\n",
        "\n",
        "    story_category: StoryCategory = Field(..., description=\"Category of the story. Examples: reinforcement_learning, theory, applications.\")\n",
        "\n",
        "    story_entities: List[Entity] = Field(..., min_items=1, max_items=10,\n",
        "                                        description=\"Entities mentioned in the story, such as algorithms, mathematical formulas, and applications.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6838nmZ5Nsl"
      },
      "outputs": [],
      "source": [
        "details_extraction_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\\n\".join([\n",
        "            \"You are an NLP data paraser.\",\n",
        "            \"You will be provided by an Arabic text associated with a Pydantic scheme.\",\n",
        "            \"Generate the ouptut in the same story language.\",\n",
        "            \"You have to extract JSON details from text according the Pydantic details.\",\n",
        "            \"Extract details as mentioned in text.\",\n",
        "            \"Do not generate any introduction or conclusion.\"\n",
        "        ])\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\\n\".join([\n",
        "            \"## Story:\",\n",
        "            story.strip(),\n",
        "            \"\",\n",
        "\n",
        "            \"## Pydantic Details:\",\n",
        "            json.dumps(\n",
        "                NewsDetails.model_json_schema(), ensure_ascii=False\n",
        "            ),\n",
        "            \"\",\n",
        "\n",
        "            \"## Story Details:\",\n",
        "            \"```json\"\n",
        "        ])\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1E3YIOW-f_1"
      },
      "source": [
        "### Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6J9rGpY-jmV"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "details_extraction_messages = [ \n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\\n\".join([\n",
        "            \"you ara a RL specialist \"\n",
        "            \"You will be provided with a text associated with a Pydantic schema.\",\n",
        "            \"Extract the output in the same language as the input text.\",\n",
        "            \"You have to extract details in JSON format based on the Pydantic details.\",\n",
        "            \"Extract details mentioned in the syllabus, including key learning outcomes, topics, and course details.\",\n",
        "            \"Do not generate any introduction or conclusion.\"\n",
        "        ])\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\\n\".join([\n",
        "            \"## Story:\",\n",
        "            \"\"\"Course Title: Reinforcement Learning (21h)\n",
        "Duration: 7 weeks (3h per week)\n",
        "Reference: Sutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An Introduction.\n",
        "\n",
        "Course Learning Outcomes (CLOs):\n",
        "By the end of the course, students will be able to:\n",
        "- Explain fundamental concepts of Reinforcement Learning (RL) and its differences from other Machine Learning paradigms. (Understand - Level 2)\n",
        "- Formulate decision-making problems as Markov Decision Processes (MDPs). (Apply - Level 3)\n",
        "- Implement RL algorithms, including Dynamic Programming, Monte Carlo methods, Temporal Difference learning, Q-learning, and Deep Q Networks (DQN). (Apply - Level 3)\n",
        "- Analyze trade-offs between model-based and model-free RL, and policy-based vs. value-based approaches. (Analyze - Level 4)\n",
        "- Evaluate the performance of RL agents in various environments. (Evaluate - Level 5)\n",
        "- Discuss recent RL advancements, such as Deep RL and applications like ChatGPT. (Evaluate - Level 5)\n",
        "\n",
        "Course Outline (Week-by-Week Plan)\n",
        "Week 1: Introduction to Reinforcement Learning\n",
        "- Topics: What is RL? Differences between RL, supervised, and unsupervised learning. Examples of RL applications. Elements of an RL problem: agents, states, actions, rewards. Exploration vs. Exploitation.\n",
        "- ILO: Explain how RL differs from other ML paradigms. (Understand - Level 2). Describe fundamental RL concepts. (Understand - Level 2)\n",
        "- Activity: Discussion on real-world RL applications (e.g., robotics, gaming, recommendation systems).\n",
        "\n",
        "Week 2: Markov Decision Processes (MDPs)\n",
        "- Topics: Definition of an MDP. States, actions, transition probabilities, rewards, discounting. Bellman equations.\n",
        "- ILO: Formulate problems as MDPs. (Apply - Level 3). Solve simple MDPs using Bellman equations. (Apply - Level 3)\n",
        "- Activity: Hands-on exercise translating real-world problems into MDPs.\n",
        "\n",
        "Week 3: Dynamic Programming (DP)\n",
        "- Topics: Policy evaluation. Policy iteration vs. value iteration. Limitations of DP.\n",
        "- ILO: Implement policy evaluation and policy iteration. (Apply - Level 3). Analyze the limitations of DP in large state spaces. (Analyze - Level 4)\n",
        "- Activity: Coding DP-based value iteration.\n",
        "\n",
        "Week 4: Monte Carlo and Temporal Difference Learning\n",
        "- Topics: Monte Carlo methods for estimating returns. Temporal Difference (TD) learning: TD(0), TD(λ). Eligibility traces.\n",
        "- ILO: Compare Monte Carlo and TD methods. (Analyze - Level 4). Implement Monte Carlo and TD algorithms. (Apply - Level 3)\n",
        "- Activity: Implementing first-visit Monte Carlo and TD(0) in Python.\n",
        "\n",
        "Week 5: Model-Free Learning and Q-Learning\n",
        "- Topics: Model-based vs. model-free RL. Q-learning and SARSA. Off-policy vs. on-policy learning. Function approximation in RL.\n",
        "- ILO: Differentiate model-based and model-free approaches. (Understand - Level 2). Implement Q-learning and SARSA. (Apply - Level 3)\n",
        "- Activity: Coding Q-learning in an OpenAI Gym environment.\n",
        "\n",
        "Week 6: Deep Reinforcement Learning & DQN\n",
        "- Topics: Introduction to Deep RL. Deep Q Networks (DQN) and experience replay. Policy-based RL: REINFORCE, Actor-Critic methods.\n",
        "- ILO: Implement a DQN using PyTorch/TensorFlow. (Apply - Level 3). Analyze the stability issues in Deep RL. (Analyze - Level 4)\n",
        "- Activity: Training a DQN on a simple RL task (CartPole).\n",
        "\n",
        "Week 7: RL at Scale & Recent Use Cases\n",
        "- Topics: RL in the large: sample efficiency, generalization, scaling RL models. RL in ChatGPT and large-scale AI systems. Ethical and practical concerns in RL applications.\n",
        "- ILO: Discuss large-scale RL challenges. (Evaluate - Level 5). Analyze RL applications in NLP (e.g., ChatGPT). (Analyze - Level 4)\n",
        "- Activity: Case study on RLHF (Reinforcement Learning from Human Feedback) in ChatGPT.\n",
        "\n",
        "Assessment and Evaluation\n",
        "- Assessment Weight (%) CLOs Assessed:\n",
        "- Coding Labs 30% (CLO 3, 4, 5)\n",
        "- Final EXAM (MCQs) 40% (CLO 1, 2, 3, 4, 5, 6)\"\"\",\n",
        "            \"\",\n",
        "            \"## Pydantic Details:\",\n",
        "            json.dumps(\n",
        "                NewsDetails.model_json_schema(), ensure_ascii=False\n",
        "            ),\n",
        "            \"\",\n",
        "            \"## Story Details:\",\n",
        "            \"```json\"\n",
        "        ])\n",
        "    }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkVOXy3y7YI_"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Au-Yng57ZZD"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype = torch_dtype\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T3NyBjaRn1i"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = tokenizer.apply_chat_template(\n",
        "    details_extraction_messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    model_inputs.input_ids,\n",
        "    max_new_tokens=1024,\n",
        "    do_sample=False, top_k=None, temperature=None, top_p=None,\n",
        ")\n",
        "\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):]\n",
        "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqSsu4dg_qYd"
      },
      "outputs": [],
      "source": [
        "text = tokenizer.apply_chat_template(\n",
        "    translation_messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    model_inputs.input_ids,\n",
        "    max_new_tokens=1024,\n",
        "    do_sample=False, top_k=None, temperature=None, top_p=None,\n",
        ")\n",
        "\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):]\n",
        "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAy8s4WtAJkn"
      },
      "source": [
        "## Evaluate OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUzk0STHALVi"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "openai_client = OpenAI(\n",
        "    api_key=userdata.get('openai-colab'),\n",
        "\n",
        ")\n",
        "\n",
        "openai_model_id = \"gpt-4o-mini\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ADnZXKdAIgN"
      },
      "outputs": [],
      "source": [
        "chat_completion = openai_client.chat.completions.create(\n",
        "    messages=details_extraction_messages,\n",
        "    model=openai_model_id,\n",
        "    temperature=0.2,\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9mH1TX2A9n7"
      },
      "outputs": [],
      "source": [
        "chat_completion = openai_client.chat.completions.create(\n",
        "    messages=translation_messages,\n",
        "    model=openai_model_id,\n",
        "    temperature=0.2,\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3seAQTZJEv3G"
      },
      "outputs": [],
      "source": [
        "json.loads(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWCWwnYiBUY0"
      },
      "source": [
        "## Knowledge Distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RBNZW5jBvVe",
        "outputId": "e568b953-18cc-4041-b9be-e2f769b877f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw data: 2400\n"
          ]
        }
      ],
      "source": [
        "raw_data_path = join(data_dir, \"datasets\", \"news-sample.jsonl\")\n",
        "\n",
        "raw_data = []\n",
        "for line in open(raw_data_path):\n",
        "    if line.strip() == \"\":\n",
        "        continue\n",
        "\n",
        "    raw_data.append(\n",
        "        json.loads(line.strip())\n",
        "    )\n",
        "\n",
        "random.Random(101).shuffle(raw_data)\n",
        "\n",
        "print(f\"Raw data: {len(raw_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIQYhOO_DHdm"
      },
      "outputs": [],
      "source": [
        "cloud_model_id = \"gpt-4o-mini\"\n",
        "price_per_1m_input_tokens = 0.150\n",
        "price_per_1m_output_tokens = 0.600\n",
        "\n",
        "prompt_tokens = 0\n",
        "completion_tokens = 0\n",
        "\n",
        "save_to = join(data_dir, \"datasets\", \"sft.jsonl\")\n",
        "\n",
        "ix = 0\n",
        "for story in tqdm(raw_data):\n",
        "\n",
        "    sample_details_extraction_messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"\\n\".join([\n",
        "                \"You are an NLP data paraser.\",\n",
        "                \"You will be provided by an Arabic text associated with a Pydantic scheme.\",\n",
        "                \"Generate the ouptut in the same story language.\",\n",
        "                \"You have to extract JSON details from text according the Pydantic details.\",\n",
        "                \"Extract details as mentioned in text.\",\n",
        "                \"Do not generate any introduction or conclusion.\"\n",
        "            ])\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\\n\".join([\n",
        "                \"## Story:\",\n",
        "                story['content'].strip(),\n",
        "                \"\",\n",
        "\n",
        "                \"## Pydantic Details:\",\n",
        "                json.dumps(\n",
        "                    NewsDetails.model_json_schema(), ensure_ascii=False\n",
        "                ),\n",
        "                \"\",\n",
        "\n",
        "                \"## Story Details:\",\n",
        "                \"```json\"\n",
        "            ])\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    response = openai_client.chat.completions.create(\n",
        "                            messages=sample_details_extraction_messages,\n",
        "                            model=cloud_model_id,\n",
        "                            temperature=0.2,\n",
        "                        )\n",
        "\n",
        "    if response.choices[0].finish_reason != \"stop\":\n",
        "        prompt_tokens += response.usage.prompt_tokens\n",
        "        continue\n",
        "\n",
        "    llm_response = response.choices[0].message.content\n",
        "    llm_resp_dict = parse_json(llm_response)\n",
        "\n",
        "    if not llm_resp_dict:\n",
        "        continue\n",
        "\n",
        "    with open(save_to, \"a\", encoding=\"utf8\") as dest:\n",
        "        dest.write(json.dumps({\n",
        "            \"id\": ix,\n",
        "            \"story\": story['content'].strip(),\n",
        "            \"task\": \"Extrat the story details into a JSON.\",\n",
        "            \"output_scheme\": json.dumps( NewsDetails.model_json_schema(), ensure_ascii=False ),\n",
        "            \"response\": llm_resp_dict,\n",
        "        }, ensure_ascii=False, default=str)  + \"\\n\" )\n",
        "\n",
        "    ix += 1\n",
        "    prompt_tokens += response.usage.prompt_tokens\n",
        "    completion_tokens += response.usage.completion_tokens\n",
        "\n",
        "    if(ix % 3) == 0:\n",
        "        cost_input = (prompt_tokens / 1_000_000) * price_per_1m_input_tokens\n",
        "        cost_output = (completion_tokens / 1_000_000) * price_per_1m_output_tokens\n",
        "        total_cost = cost_input + cost_output\n",
        "\n",
        "        print(f\"Iteration {ix}: Total Cost = ${total_cost:.4f} \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEV0rL5LHaIy"
      },
      "outputs": [],
      "source": [
        "cloud_model_id = \"gpt-4o-mini\"\n",
        "price_per_1m_input_tokens = 0.150\n",
        "price_per_1m_output_tokens = 0.600\n",
        "\n",
        "prompt_tokens = 0\n",
        "completion_tokens = 0\n",
        "\n",
        "save_to = join(data_dir, \"datasets\", \"sft.jsonl\")\n",
        "\n",
        "ix = 0\n",
        "for story in tqdm(raw_data):\n",
        "\n",
        "    for targeted_lang in [\"English\", \"French\"]:\n",
        "        sample_translation_messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\\n\".join([\n",
        "                    \"You are a professional translator.\",\n",
        "                    \"You will be provided by an Arabic text.\",\n",
        "                    \"You have to translate the text into the `Targeted Language`.\",\n",
        "                    \"Follow the provided Scheme to generate a JSON\",\n",
        "                    \"Do not generate any introduction or conclusion.\"\n",
        "                ])\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"\\n\".join([\n",
        "                    \"## Pydantic Details:\",\n",
        "                    json.dumps( TranslatedStory.model_json_schema(), ensure_ascii=False ),\n",
        "                    \"\",\n",
        "\n",
        "                    \"## Targeted Language or Dialect:\",\n",
        "                    targeted_lang,\n",
        "                    \"\",\n",
        "\n",
        "                    \"## Story:\",\n",
        "                    story['content'].strip(),\n",
        "                    \"\",\n",
        "\n",
        "                    \"## Translated Story:\",\n",
        "                    \"```json\"\n",
        "                ])\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        response = openai_client.chat.completions.create(\n",
        "                                messages=sample_translation_messages,\n",
        "                                model=cloud_model_id,\n",
        "                                temperature=0.2,\n",
        "                            )\n",
        "\n",
        "        if response.choices[0].finish_reason != \"stop\":\n",
        "            prompt_tokens += response.usage.prompt_tokens\n",
        "            continue\n",
        "\n",
        "        llm_response = response.choices[0].message.content\n",
        "        llm_resp_dict = parse_json(llm_response)\n",
        "\n",
        "        if not llm_resp_dict:\n",
        "            continue\n",
        "\n",
        "        with open(save_to, \"a\", encoding=\"utf8\") as dest:\n",
        "            dest.write(json.dumps({\n",
        "                \"id\": ix,\n",
        "                \"story\": story['content'].strip(),\n",
        "\n",
        "                \"output_scheme\": json.dumps( TranslatedStory.model_json_schema(), ensure_ascii=False ),\n",
        "                \"task\": f\"You have to translate the story content into {targeted_lang} associated with a title into a JSON.\",\n",
        "\n",
        "                \"response\": llm_resp_dict,\n",
        "            }, ensure_ascii=False, default=str)  + \"\\n\" )\n",
        "\n",
        "        ix += 1\n",
        "        prompt_tokens += response.usage.prompt_tokens\n",
        "        completion_tokens += response.usage.completion_tokens\n",
        "\n",
        "        if(ix % 3) == 0:\n",
        "            cost_input = (prompt_tokens / 1_000_000) * price_per_1m_input_tokens\n",
        "            cost_output = (completion_tokens / 1_000_000) * price_per_1m_output_tokens\n",
        "            total_cost = cost_input + cost_output\n",
        "\n",
        "            print(f\"Iteration {ix}: Total Cost = ${total_cost:.4f} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBbGFkVEH1X-"
      },
      "source": [
        "## Format Finetuning Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bn4uUuDOIO3D"
      },
      "outputs": [],
      "source": [
        "\n",
        "sft_data_path = join(data_dir, \"datasets\", \"sft.jsonl\")\n",
        "llm_finetunning_data = []\n",
        "\n",
        "system_message = \"\\n\".join([\n",
        "    \"You are a professional NLP data parser.\",\n",
        "    \"Follow the provided `Task` by the user and the `Output Scheme` to generate the `Output JSON`.\",\n",
        "    \"Do not generate any introduction or conclusion.\"\n",
        "])\n",
        "\n",
        "for line in open(sft_data_path):\n",
        "    if line.strip() == \"\":\n",
        "        continue\n",
        "\n",
        "    rec = json.loads(line.strip())\n",
        "\n",
        "    llm_finetunning_data.append({\n",
        "        \"system\": system_message,\n",
        "        \"instruction\": \"\\n\".join([\n",
        "            \"# Story:\",\n",
        "            rec[\"story\"],\n",
        "\n",
        "            \"# Task:\",\n",
        "            rec[\"task\"],\n",
        "\n",
        "            \"# Output Scheme:\",\n",
        "            rec[\"output_scheme\"],\n",
        "            \"\",\n",
        "\n",
        "            \"# Output JSON:\",\n",
        "            \"```json\"\n",
        "\n",
        "        ]),\n",
        "        \"input\": \"\",\n",
        "        \"output\": \"\\n\".join([\n",
        "            \"```json\",\n",
        "            json.dumps(rec[\"response\"], ensure_ascii=False, default=str),\n",
        "            \"```\"\n",
        "        ]),\n",
        "        \"history\": []\n",
        "    })\n",
        "\n",
        "random.Random(101).shuffle(llm_finetunning_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUXpYjfAIfKb",
        "outputId": "41719811-27dc-4074-adfe-e094a19b3a10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2766"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(llm_finetunning_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvWmfB-QPJUs"
      },
      "outputs": [],
      "source": [
        "train_sample_sz = 2700\n",
        "\n",
        "train_ds = llm_finetunning_data[:train_sample_sz]\n",
        "eval_ds = llm_finetunning_data[train_sample_sz:]\n",
        "\n",
        "os.makedirs(join(data_dir, \"datasets\", \"llamafactory-finetune-data\"), exist_ok=True)\n",
        "\n",
        "with open(join(data_dir, \"datasets\", \"llamafactory-finetune-data\", \"train.json\"), \"w\") as dest:\n",
        "    json.dump(train_ds, dest, ensure_ascii=False, default=str)\n",
        "\n",
        "with open(join(data_dir, \"datasets\", \"llamafactory-finetune-data\", \"val.json\"), \"w\", encoding=\"utf8\") as dest:\n",
        "    json.dump(eval_ds, dest, ensure_ascii=False, default=str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3mkuT7i6P6Uz",
        "outputId": "642d18b9-5acf-43a1-8edb-1967a59318fc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/gdrive/MyDrive/youtube-resources/llm-finetuning/datasets/llamafactory-finetune-data/val.json'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "join(data_dir, \"datasets\", \"llamafactory-finetune-data\", \"val.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoBc56BiRDLO"
      },
      "source": [
        "## Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMTk3i2fQKk5"
      },
      "outputs": [],
      "source": [
        "# # Configure LLaMA-Factory for the new datasets\n",
        "\n",
        "# # update /content/LLaMA-Factory/data/dataset_info.json and append\n",
        "# ```\n",
        "   \"news_finetune_train\": {\n",
        "        \"file_name\": \"/gdrive/MyDrive/youtube-resources/llm-finetuning/datasets/llamafactory-finetune-data/train.json\",\n",
        "        \"columns\": {\n",
        "            \"prompt\": \"instruction\",\n",
        "            \"query\": \"input\",\n",
        "            \"response\": \"output\",\n",
        "            \"system\": \"system\",\n",
        "            \"history\": \"history\"\n",
        "        }\n",
        "    },\n",
        "    \"news_finetune_val\": {\n",
        "        \"file_name\": \"/gdrive/MyDrive/youtube-resources/llm-finetuning/datasets/llamafactory-finetune-data/val.json\",\n",
        "        \"columns\": {\n",
        "            \"prompt\": \"instruction\",\n",
        "            \"query\": \"input\",\n",
        "            \"response\": \"output\",\n",
        "            \"system\": \"system\",\n",
        "            \"history\": \"history\"\n",
        "        }\n",
        "    }\n",
        "# ```\n",
        "\n",
        "# https://wandb.ai/mr-bakrianoo/llamafactory/runs/apwbkni9\n",
        "# https://wandb.ai/mr-bakrianoo/llamafactory/runs/c5tf0q90"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCWgFdsoQrow",
        "outputId": "4a48543d-52b6-4a9f-ef72-84ffb674a56a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/LLaMA-Factory/examples/train_lora/news_finetune.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/LLaMA-Factory/examples/train_lora/news_finetune.yaml\n",
        "\n",
        "### model\n",
        "model_name_or_path: Qwen/Qwen2.5-1.5B-Instruct\n",
        "trust_remote_code: true\n",
        "\n",
        "### method\n",
        "stage: sft\n",
        "do_train: true\n",
        "finetuning_type: lora\n",
        "lora_rank: 64\n",
        "lora_target: all\n",
        "\n",
        "### dataset\n",
        "dataset: news_finetune_train\n",
        "eval_dataset: news_finetune_val\n",
        "template: qwen\n",
        "cutoff_len: 3500\n",
        "# max_samples: 50\n",
        "overwrite_cache: true\n",
        "preprocessing_num_workers: 16\n",
        "\n",
        "### output\n",
        "# resume_from_checkpoint: /gdrive/MyDrive/youtube-resources/llm-finetuning/models/checkpoint-1500\n",
        "output_dir: /gdrive/MyDrive/youtube-resources/llm-finetuning/models/\n",
        "logging_steps: 10\n",
        "save_steps: 500\n",
        "plot_loss: true\n",
        "# overwrite_output_dir: true\n",
        "\n",
        "### train\n",
        "per_device_train_batch_size: 1\n",
        "gradient_accumulation_steps: 4\n",
        "learning_rate: 1.0e-4\n",
        "num_train_epochs: 3.0\n",
        "lr_scheduler_type: cosine\n",
        "warmup_ratio: 0.1\n",
        "bf16: true\n",
        "ddp_timeout: 180000000\n",
        "\n",
        "### eval\n",
        "# val_size: 0.1\n",
        "per_device_eval_batch_size: 1\n",
        "eval_strategy: steps\n",
        "eval_steps: 100\n",
        "\n",
        "report_to: wandb\n",
        "run_name: newsx-finetune-llamafactory\n",
        "\n",
        "push_to_hub: true\n",
        "export_hub_model_id: \"bakrianoo/news-analyzer\"\n",
        "hub_private_repo: true\n",
        "hub_strategy: checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wkigp2KPVgqU"
      },
      "outputs": [],
      "source": [
        "!cd LLaMA-Factory/ && llamafactory-cli train /content/LLaMA-Factory/examples/train_lora/news_finetune.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeKBEof7Xa6a"
      },
      "source": [
        "## New Finetuned Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXG625DZXcrT"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype = torch_dtype\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXzybVp2X048"
      },
      "outputs": [],
      "source": [
        "finetuned_model_id = \"/gdrive/MyDrive/youtube-resources/llm-finetuning/models\"\n",
        "model.load_adapter(finetuned_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M45kdkH-XXmu"
      },
      "outputs": [],
      "source": [
        "def generate_resp(messages):\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "    generated_ids = model.generate(\n",
        "        model_inputs.input_ids,\n",
        "        max_new_tokens=1024,\n",
        "        do_sample=False, top_k=None, temperature=None, top_p=None,\n",
        "    )\n",
        "\n",
        "    generated_ids = [\n",
        "        output_ids[len(input_ids):]\n",
        "        for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "    ]\n",
        "\n",
        "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "    return response\n",
        "\n",
        "response = generate_resp(translation_messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IghFtP0XtvE"
      },
      "outputs": [],
      "source": [
        "parse_json(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LtXq5y95CA1"
      },
      "outputs": [],
      "source": [
        "class Generator:\n",
        "    def __init__(self, model, tokenizer):\n",
        "\n",
        "        self.model, self.tokenizer = model, tokenizer\n",
        "        self.mask = None\n",
        "\n",
        "    def generate(self, messages:list, max_new_tokens: int=2000, temperature:float=0.1):\n",
        "\n",
        "        def logits_processor(token_ids, logits):\n",
        "          # logits_processor default recieve the logits which is the score matrix of each time-step\n",
        "          \"\"\"\n",
        "          \"\"\"\n",
        "          if self.mask is None:\n",
        "              # as we don't know where the Chinses tokens locate at which index\n",
        "              # in the vocabulary but we know how it looks like and the range of it\n",
        "\n",
        "              # decode all the tokens in the vocabulary in order\n",
        "              token_ids = torch.arange(logits.size(-1))\n",
        "              decoded_tokens = self.tokenizer.batch_decode(token_ids.unsqueeze(1), skip_special_tokens=True)\n",
        "\n",
        "              # create a mask tensor to exclude positions of Chinese characters.\n",
        "              # since this process uses a for loop and is time-consuming,\n",
        "              # the result will be stored as a property for later use to ensure it only runs once.\n",
        "              self.mask = torch.tensor([\n",
        "                  # loop through each token in the vocabulary and compare it to Chinese characters.\n",
        "                  any(0x4E00 <= ord(c) <= 0x9FFF or 0x3400 <= ord(c) <= 0x4DBF or 0xF900 <= ord(c) <= 0xFAFF for c in\n",
        "                      token)\n",
        "                  for token in decoded_tokens\n",
        "              ])\n",
        "\n",
        "          # mask the score by - inf\n",
        "          logits[:, self.mask] = -float(\"inf\")\n",
        "          return logits\n",
        "\n",
        "        # this step transforms the messages into a string,\n",
        "        # adding special tokens e.g separate tokens between system content user queries\n",
        "        text = self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True,\n",
        "        )\n",
        "\n",
        "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.model.device)\n",
        "\n",
        "        generated_ids = self.model.generate(\n",
        "            **model_inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=temperature,\n",
        "            # add the logits_processor here\n",
        "            logits_processor=[logits_processor]\n",
        "        )\n",
        "        generated_ids = [\n",
        "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "        ]\n",
        "        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "        return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsA7F8wD5XVG"
      },
      "outputs": [],
      "source": [
        "# define an object\n",
        "llm = Generator(model, tokenizer)\n",
        "\n",
        "# generate a response without chinese characters\n",
        "response = llm.generate(details_extraction_messages)\n",
        "print( parse_json(response) )\n",
        "\n",
        "response = llm.generate(translation_messages)\n",
        "print( parse_json(response) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC9_nqQaZKWx"
      },
      "source": [
        "## Cost Estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FK_FWdKeZMnE"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from faker import Faker\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "start_time = datetime.now()\n",
        "fake = Faker('ar')\n",
        "\n",
        "input_tokens = 0\n",
        "output_tokens = 0\n",
        "\n",
        "for i in tqdm(range(30)):\n",
        "    prompt = fake.text(max_nb_chars=random.randint(150, 200))\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    response = generate_resp(messages)\n",
        "\n",
        "    input_tokens += len(tokenizer.apply_chat_template(messages))\n",
        "    output_tokens += len(tokenizer.encode(response))\n",
        "\n",
        "total_time = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "print(f\"Total Time: {total_time} seconds\")\n",
        "print(f\"Input Tokens: {input_tokens}\")\n",
        "print(f\"Output Tokens: {output_tokens}\")\n",
        "print(f\"Total Tokens: {input_tokens + output_tokens}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5qgKwWWakuM"
      },
      "outputs": [],
      "source": [
        "# Total Time: 387.838115 seconds\n",
        "# Input Tokens: 2446\n",
        "# Output Tokens: 7375\n",
        "# Total Tokens: 9821"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQRCACPaZwOf",
        "outputId": "75ece51c-9575-4d74-8687-87f8ba16a904"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25.311855670103093"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "9821  / 388"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOC2oP97bkOi"
      },
      "source": [
        "## vLLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr72ssnKbrwH",
        "outputId": "0801150e-5793-42d1-e91c-bcac13ce25ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ],
      "source": [
        "base_model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "adapter_model_id = \"/gdrive/MyDrive/youtube-resources/llm-finetuning/models\"\n",
        "\n",
        "\n",
        "!nohup vllm serve \"{base_model_id}\" --dtype=half --gpu-memory-utilization 0.8 --max_lora_rank 64 --enable-lora --lora-modules news-lora=\"{adapter_model_id}\" &\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHMHHfA9dLta"
      },
      "outputs": [],
      "source": [
        "!tail -n 30 nohup.out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBZ2Du8tdjSy"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6Gor_fVdW-U"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(\n",
        "    translation_messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYPDkJ_Adp7N"
      },
      "outputs": [],
      "source": [
        "vllm_model_id = \"news-lora\"\n",
        "\n",
        "llm_response = requests.post(\"http://localhost:8000/v1/completions\", json={\n",
        "    \"model\": vllm_model_id,\n",
        "    \"prompt\": prompt,\n",
        "    \"max_tokens\": 1000,\n",
        "    \"temperature\": 0.3\n",
        "})\n",
        "\n",
        "llm_response.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3p1nGLyedA8"
      },
      "source": [
        "## Load Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOZYakDneeoD",
        "outputId": "5bef29a9-235a-4032-8f80-f16ecdd3c1d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting locust.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile locust.py\n",
        "\n",
        "import random\n",
        "import json\n",
        "from locust import HttpUser, task, between, constant\n",
        "from transformers import AutoTokenizer\n",
        "from faker import Faker\n",
        "\n",
        "fake = Faker('ar')\n",
        "\n",
        "class CompletionLoadTest(HttpUser):\n",
        "    wait_time = between(1, 3)\n",
        "\n",
        "    @task\n",
        "    def post_completion(self):\n",
        "        model_id = \"news-lora\"\n",
        "        prompt = fake.text(max_nb_chars=random.randint(150, 200))\n",
        "\n",
        "        message = {\n",
        "            \"model\": model_id,\n",
        "            \"prompt\": prompt,\n",
        "            \"max_tokens\": 512,\n",
        "            \"temperature\": 0.3\n",
        "        }\n",
        "\n",
        "        llm_response = self.client.post(\"/v1/completions\", json=message)\n",
        "\n",
        "        if llm_response.status_code == 200:\n",
        "            with open(\"./vllm_tokens.txt\", \"a\") as dest:\n",
        "                dest.write(json.dumps({\n",
        "                    \"prompt\": prompt,\n",
        "                    \"response\": llm_response.json()[\"choices\"][0][\"text\"],\n",
        "                }, ensure_ascii=False) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYPw83hzfeNb"
      },
      "outputs": [],
      "source": [
        "!locust --headless -f locust.py --host=http://localhost:8000 -u 20 -r 1 -t \"60s\" --html=locust_results.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZFSPbufiYbk"
      },
      "outputs": [],
      "source": [
        "vllm_tokens = [\n",
        "    json.loads(line.strip())\n",
        "    for line in open(\"./vllm_tokens.txt\") if line.strip() != \"\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCwHMzVnigg9",
        "outputId": "07a15b5d-93b9-46ff-96d8-84241066bc75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Input Tokens: 2662\n",
            "Total Output Tokens: 37840\n"
          ]
        }
      ],
      "source": [
        "base_model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
        "\n",
        "total_input_tokens = sum([ len(tokenizer.encode(rec['prompt'])) for rec in vllm_tokens ])\n",
        "total_output_tokens = sum([ len(tokenizer.encode(rec['response'])) for rec in vllm_tokens ])\n",
        "\n",
        "print(f\"Total Input Tokens: {total_input_tokens}\")\n",
        "print(f\"Total Output Tokens: {total_output_tokens}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOpAbHLSioBz",
        "outputId": "424330d7-ed80-40bd-97e1-ab5a5d16142a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "630.6666666666666"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "37840 / 60"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "R4gFkGQA4_BW"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
